{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](1_bDwEvCRgrKVbLrAXEixpfA.png)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline \n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import functools as ft\n",
    "\n",
    "#natural language processing\n",
    "#pip install nltk\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "\n",
    "#bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#classification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Analysis II\n",
    "    a) Importing data\n",
    "    \n",
    "    b) TF-IDF\n",
    "        i) Unigram\n",
    "       ii) Bigram\n",
    "      iii) Trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10062, 22)\n"
     ]
    }
   ],
   "source": [
    "#import cleaned2_data.csv file\n",
    "cleaned2_df = pd.read_csv(\"cleaned2_data.csv\")\n",
    "\n",
    "cleaned2_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "print(cleaned2_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10062, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blurb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>treehouse cornell take architecture new height...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>track collection new original musical piece jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>juxtaposing delicious food good friend unsettl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>melody mus tell story melody struggle encounte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mission help build passion science teaching ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               blurb\n",
       "0  treehouse cornell take architecture new height...\n",
       "1  track collection new original musical piece jo...\n",
       "2  juxtaposing delicious food good friend unsettl...\n",
       "3  melody mus tell story melody struggle encounte...\n",
       "4  mission help build passion science teaching ne..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import corpus_data.csv file\n",
    "corpus_df = pd.read_csv(\"corpus_data.csv\")\n",
    "\n",
    "corpus_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "print(corpus_df.shape)\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for NaN Values in corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [blurb]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "is_NaN = corpus_df.isna()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = corpus_df[row_has_NaN]\n",
    "print(rows_with_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blurb    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(corpus_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individually split and tokenize 'blurb' column words before splitting into bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    treehouse cornell take architecture new height...\n",
       "1    track collection new original musical piece jo...\n",
       "2    juxtaposing delicious food good friend unsettl...\n",
       "3    melody mus tell story melody struggle encounte...\n",
       "4    mission help build passion science teaching ne...\n",
       "Name: blurb, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df['blurb'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [treehouse, cornell, take, architecture, new, ...\n",
       "1    [track, collection, new, original, musical, pi...\n",
       "2    [juxtaposing, delicious, food, good, friend, u...\n",
       "3    [melody, mus, tell, story, melody, struggle, e...\n",
       "4    [mission, help, build, passion, science, teach...\n",
       "Name: blurb, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenize = corpus_df['blurb'].apply(lambda x: word_tokenize(x))\n",
    "corpus_tokenize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(treehouse, cornell), (cornell, take), (take,...\n",
       "1    [(track, collection), (collection, new), (new,...\n",
       "2    [(juxtaposing, delicious), (delicious, food), ...\n",
       "3    [(melody, mus), (mus, tell), (tell, story), (s...\n",
       "4    [(mission, help), (help, build), (build, passi...\n",
       "Name: blurb, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bigrams_series = corpus_tokenize.apply(lambda row: list(nltk.ngrams(row, 2)))\n",
    "corpus_bigrams_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) TF-IDF (Unigrams, Bigrams, and Trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i) Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "10062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        treehouse cornell take architecture new height...\n",
       "1        track collection new original musical piece jo...\n",
       "2        juxtaposing delicious food good friend unsettl...\n",
       "3        melody mus tell story melody struggle encounte...\n",
       "4        mission help build passion science teaching ne...\n",
       "                               ...                        \n",
       "10057    aim create timeless song teach thing god gener...\n",
       "10058    multimedia memoir film formed tapestry prose p...\n",
       "10059    heliopolis small storefront located greenpoint...\n",
       "10060    inspiring jewish chant song peace joyful harmo...\n",
       "10061    torrefy need help printing first run new album...\n",
       "Name: blurb, Length: 10062, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entire corpus series into seperate strings\n",
    "corpus_series = corpus_df['blurb'].apply(lambda x: str(x))\n",
    "print(type(corpus_series[0]))\n",
    "\n",
    "print(len(corpus_series))\n",
    "corpus_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "           term        rank\n",
      "6531      help  165.897106\n",
      "9718       new  139.641998\n",
      "772        art  110.369324\n",
      "1628      book  109.002543\n",
      "344      album  105.287112\n",
      "5289      film   98.879661\n",
      "9520     music   95.619674\n",
      "5339     first   95.034016\n",
      "15856    world   94.677695\n",
      "9664      need   92.269544\n",
      "8630      make   90.094293\n",
      "13729    story   89.440586\n",
      "8217      life   87.469702\n",
      "10068      one   80.539478\n",
      "8440      love   79.839196\n",
      "11249  project   72.909087\n",
      "5901       get   72.752287\n",
      "12781   series   69.188033\n",
      "15959     year   68.964040\n",
      "790     artist   67.600017\n"
     ]
    }
   ],
   "source": [
    "#getting unigrams  \n",
    "vectorizer = CountVectorizer() \n",
    "X1 = vectorizer.fit_transform(corpus_series)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "\n",
    "#applying TFIDF for unigrams\n",
    "vectorizer = TfidfVectorizer() \n",
    "X2 = vectorizer.fit_transform(corpus_series) \n",
    "scores = (X2.toarray()) \n",
    "\n",
    "#getting top-ranking features \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "for col, term in enumerate(features): \n",
    "    data1.append( (term, sums[0, col] )) \n",
    "ranking = pd.DataFrame(data1, columns = ['term', 'rank']) \n",
    "words = (ranking.sort_values('rank', ascending = False)) \n",
    "print (\"\\n\\nWords : \\n\", words.head(20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii) Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "                 term       rank\n",
      "22017     enamel pin  36.526032\n",
      "47828      need help  34.470738\n",
      "63506     short film  28.892953\n",
      "28675    full length  17.507847\n",
      "53917   playing card  17.367218\n",
      "32445    hard enamel  16.744082\n",
      "33161      help fund  16.187890\n",
      "11537     child book  15.608867\n",
      "46995    music video  15.084399\n",
      "33237      help make  14.447327\n",
      "31352  graphic novel  13.243412\n",
      "18058    debut album  12.866378\n",
      "33166       help get  12.564496\n",
      "48134      new album  12.453750\n",
      "4707   award winning  12.401338\n",
      "40140   length album  12.158833\n",
      "61448         sci fi  11.368919\n",
      "33061     help bring  11.210558\n",
      "78912       year old  11.089349\n",
      "76490     web series  10.895128\n"
     ]
    }
   ],
   "source": [
    "#getting bigrams  \n",
    "vectorizer = CountVectorizer(ngram_range =(2, 2)) \n",
    "X1 = vectorizer.fit_transform(corpus_series)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "\n",
    "#applying TFIDF for bigrams\n",
    "vectorizer = TfidfVectorizer(ngram_range =(2, 2)) \n",
    "X2 = vectorizer.fit_transform(corpus_series) \n",
    "scores = (X2.toarray()) \n",
    "\n",
    "#getting top-ranking features \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "for col, term in enumerate(features): \n",
    "    data1.append( (term, sums[0, col] )) \n",
    "ranking = pd.DataFrame(data1, columns = ['term', 'rank']) \n",
    "words = (ranking.sort_values('rank', ascending = False)) \n",
    "print (\"\\n\\nWords : \\n\", words.head(20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words head : \n",
      "                           term       rank\n",
      "33752          hard enamel pin  16.407152\n",
      "29725        full length album  11.958650\n",
      "27711        first full length   6.140670\n",
      "34836         help make happen   4.672843\n",
      "51141            new york city   4.597027\n",
      "18806        deck playing card   4.413598\n",
      "22567      enamel pin inspired   4.223605\n",
      "1495           album need help   3.993997\n",
      "50120           need help make   3.770010\n",
      "63628        role playing game   3.707530\n",
      "13092        coffee table book   3.437649\n",
      "34990          help raise fund   3.112006\n",
      "50102           need help fund   3.089152\n",
      "50105            need help get   2.937158\n",
      "12009       child picture book   2.912715\n",
      "21134          dream come true   2.763573\n",
      "1518       album original song   2.707635\n",
      "18668        debut full length   2.634361\n",
      "64791  science fiction fantasy   2.542458\n",
      "22586           enamel pin set   2.491715\n"
     ]
    }
   ],
   "source": [
    "#getting trigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (3,3)) \n",
    "X1 = vectorizer.fit_transform(corpus_series)  \n",
    "features = (vectorizer.get_feature_names())  \n",
    "\n",
    "#applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (3,3)) \n",
    "X2 = vectorizer.fit_transform(corpus_series) \n",
    "scores = (X2.toarray())  \n",
    "  \n",
    "#getting top ranking features \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "for col, term in enumerate(features): \n",
    "    data1.append( (term, sums[0,col] )) \n",
    "ranking = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "words = (ranking.sort_values('rank', ascending = False)) \n",
    "print (\"\\n\\nWords head : \\n\", words.head(20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Step 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
